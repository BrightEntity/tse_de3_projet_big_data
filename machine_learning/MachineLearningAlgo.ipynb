{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\remiv\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\remiv\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des jeux de données de CV et d'étiquettes\n",
    "import pandas as pd\n",
    "df = pd.read_json('data.json')\n",
    "df.description\n",
    "label = pd.read_csv('label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                        description gender\n",
      "0         0   She is also a Ronald D. Asmus Policy Entrepre...      F\n",
      "1         1   He is a member of the AICPA and WICPA. Brent ...      M\n",
      "2         2   Dr. Aster has held teaching and research posi...      M\n",
      "4         3   He runs a boutique design studio attending cl...      M\n",
      "5         4   He focuses on cloud security, identity and ac...      M\n",
      "...     ...                                                ...    ...\n",
      "9995   8011   His most recent poetry collection is The Name...      M\n",
      "9996   8012   He is a past president of the Houston Psychol...      M\n",
      "9998   8013   He also holds an appointment in Molecular Phy...      M\n",
      "9999   8014   She has been scrapbooking since 2002, mostly ...      F\n",
      "10000  8015   She has worked in the field of disaster manag...      F\n",
      "\n",
      "[8016 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Voilà comment choisir un échantillon. On sélectionne un nombre plus petit par soucis de performances. Optionnel\n",
    "df = df.loc[0:10000]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  Category\n",
      "0        0        19\n",
      "1        1         9\n",
      "2        2        19\n",
      "3        3        24\n",
      "4        4        24\n",
      "...    ...       ...\n",
      "8011  8011        15\n",
      "8012  8012        22\n",
      "8013  8013        19\n",
      "8014  8014        11\n",
      "8015  8015        19\n",
      "\n",
      "[8016 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Voilà comment choisir un échantillon. On sélectionne un nombre plus petit par soucis de performances. Optionnel\n",
    "label = label.loc[0:8015]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Id                                        description gender\n",
      "0            0   she is also a ronald d. asmus policy entrepre...      F\n",
      "1            1   he is a member of the aicpa and wicpa. brent ...      M\n",
      "2            2   dr. aster has held teaching and research posi...      M\n",
      "4            3   he runs a boutique design studio attending cl...      M\n",
      "5            4   he focuses on cloud security, identity and ac...      M\n",
      "...        ...                                                ...    ...\n",
      "271492  217192   a member of the uwa cultural collections boar...      M\n",
      "271493  217193   kelly has worked globally leading teams of co...      F\n",
      "271494  217194   he's the lead author of a recent study that f...      M\n",
      "271495  217195   she specializes in the theoretical and pedago...      F\n",
      "271496  217196   since she was 10 years old she has become a m...      F\n",
      "\n",
      "[217197 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Phase de préprocessing : on met en minuscule pour que les mots qui commencent\n",
    "# par une majuscule et une miniscule ne soit pas compter différemment.\n",
    "df['description'] = df['description'].str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          she is also a ronald d asmus policy entrepren...\n",
      "1          he is a member of the aicpa and wicpa brent g...\n",
      "2          dr aster has held teaching and research posit...\n",
      "4          he runs a boutique design studio attending cl...\n",
      "5          he focuses on cloud security identity and acc...\n",
      "                                ...                        \n",
      "271492     a member of the uwa cultural collections boar...\n",
      "271493     kelly has worked globally leading teams of co...\n",
      "271494     hes the lead author of a recent study that fo...\n",
      "271495     she specializes in the theoretical and pedago...\n",
      "271496     since she was 10 years old she has become a m...\n",
      "Name: description, Length: 217197, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# On supprime les virgules, points...\n",
    "df['description'] = df['description'].str.replace('[^\\w\\s]','')\n",
    "print(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [she, is, also, a, ronald, d, asmus, policy, e...\n",
      "1        [he, is, a, member, of, the, aicpa, and, wicpa...\n",
      "2        [dr, aster, has, held, teaching, and, research...\n",
      "4        [he, runs, a, boutique, design, studio, attend...\n",
      "5        [he, focuses, on, cloud, security, identity, a...\n",
      "                               ...                        \n",
      "9995     [his, most, recent, poetry, collection, is, th...\n",
      "9996     [he, is, a, past, president, of, the, houston,...\n",
      "9998     [he, also, holds, an, appointment, in, molecul...\n",
      "9999     [she, has, been, scrapbooking, since, 2002, mo...\n",
      "10000    [she, has, worked, in, the, field, of, disaste...\n",
      "Name: description, Length: 8016, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# On isole chaque mot de chaque colonne afin de pouvoir les compter. Nous n'avons finalement pas exécuter cette cellule car on ne peut pas passer de colonnes tokeniser\n",
    "# en paramètre de la fonction train_test_split.\n",
    "# resumeExtractToken = resumeExtract.apply(word_tokenize)\n",
    "# print(resumeExtractToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\remiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# On applique d'autres préprocessing pour voir leur influence sur le f1 score\n",
    "# On commence par enlever les stopwords : on récupère la liste de stopwords en \n",
    "# anglais. Nous n'avons finalement pas exécuter cette cellule car on ne peut pas passer de colonnes tokeniser en paramètre de la fonction train_test_split.\n",
    "#nltk.download('stopwords')\n",
    "#stop_words = stopwords.words('english')\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [also, ronald, asmus, policy, entrepreneur, fe...\n",
      "1        [member, aicpa, wicpa, brent, graduated, unive...\n",
      "2        [dr, aster, held, teaching, research, position...\n",
      "4        [runs, boutique, design, studio, attending, cl...\n",
      "5        [focuses, cloud, security, identity, access, m...\n",
      "                               ...                        \n",
      "9995     [recent, poetry, collection, names, things, ne...\n",
      "9996     [past, president, houston, psychological, asso...\n",
      "9998     [also, holds, appointment, molecular, physiolo...\n",
      "9999     [scrapbooking, since, 2002, mostly, european, ...\n",
      "10000    [worked, field, disaster, management, 20, year...\n",
      "Name: description, Length: 8016, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Nous n'avons finalement pas exécuter cette cellule car on ne peut pas passer de colonnes tokeniser en paramètre de la fonction train_test_split.\n",
    "#resumeExtractToken = resumeExtractToken.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "#print(resumeExtractToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sépare nos extraits de CV et leurs catégories en données d'entraînement  \n",
    "# et de tests de manière aléatoire.\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(df['description'],label.Category.values, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_save = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise TfidfVectorizer pour repérer la fréquence d'apparition de chaque\n",
    "# mots présents dans nos données d'entraînements.\n",
    "transformer = TfidfVectorizer().fit(X_train.values)\n",
    "X_train = transformer.transform(X_train.values)\n",
    "X_test = transformer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remiv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\remiv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# On utilise le modèle d'apprentissage automatique régression linéaire\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152675060837723\n"
     ]
    }
   ],
   "source": [
    "# On calcule le f1_score (indicateur de précision, + on est proche de 1 + on est précis)\n",
    "# La valeur f1_score est la moyenne du f1_score pour chaque métier.\n",
    "# On effectue une pondération en fonction du nombre d'occurences d'un métier.\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 2000,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On affiche les paramètres de linear regression.\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.338321859674915\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On a vu que mettre la valeur de fit_intercept à False diminue le f1 score, donc je vais la remettre.\n",
    "model.set_params(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7294220452769585\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=4000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On a vu que le poids augmente le f1Score. On essaye maintenant d'augmenter le nombre d'itérations.\n",
    "model.set_params(max_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5885925404245664\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoir doubler le nombre d'itérations n'a eu aucun importance. Mme LACLAU nous a conseillé de tester le paramètre C. C doit être un bon compromis pour lutter contre\n",
    "# l'underfitting et l'overfitting. Et de ne prendre qu'un seul autre modèle de classification. SVM par exemple ?\n",
    "model.set_params(max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(C=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5841838844100915\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diminuer C a réduit le f1score, essayons de l'augmenter.\n",
    "model.set_params(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7455537959317455\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.25      0.38        20\n",
      "           1       0.66      0.61      0.63        41\n",
      "           2       0.73      0.73      0.73        11\n",
      "           3       0.50      0.47      0.48       111\n",
      "           4       1.00      0.40      0.57        10\n",
      "           5       0.89      0.66      0.76        38\n",
      "           6       0.61      0.85      0.71       210\n",
      "           7       1.00      0.18      0.31        11\n",
      "           8       0.73      0.63      0.68        57\n",
      "           9       0.74      0.57      0.64        30\n",
      "          10       1.00      0.18      0.31        11\n",
      "          11       0.42      0.47      0.45        59\n",
      "          12       0.54      0.54      0.54        24\n",
      "          13       0.56      0.67      0.61        54\n",
      "          14       0.61      0.71      0.66        49\n",
      "          15       0.76      0.65      0.70        52\n",
      "          16       0.62      0.38      0.48        13\n",
      "          17       0.71      0.56      0.63         9\n",
      "          18       0.76      0.73      0.74        44\n",
      "          19       0.84      0.82      0.83       899\n",
      "          20       0.76      0.85      0.80       197\n",
      "          21       0.88      0.58      0.70        12\n",
      "          22       0.66      0.58      0.62       115\n",
      "          23       1.00      0.14      0.25         7\n",
      "          24       0.60      0.54      0.57        68\n",
      "          25       0.67      0.66      0.67        44\n",
      "          26       0.77      0.78      0.78       190\n",
      "          27       0.75      0.79      0.77        19\n",
      "\n",
      "    accuracy                           0.73      2405\n",
      "   macro avg       0.74      0.57      0.61      2405\n",
      "weighted avg       0.74      0.73      0.72      2405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5914102436779226\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remiv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation d'un fichier csv des prédictions\n",
    "predict = pd.DataFrame(X_test, y_pred).to_csv('predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learning = pd.DataFrame({\n",
    "    \"Description\": X_test_save,\n",
    "    \"Metier_Reel\": Y_test,\n",
    "    \"Metier_Predit\": y_pred,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = df_learning.to_csv('predict.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(X_test, Y_test).to_csv('predict3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les tests suivant n'ont pas donnés de meilleurs résultats. Toutes les cellules suivantes sont optionnelles. Elles contiennent par contre notre test avec svm.\n",
    "# Vous pouvez exécuter les deux dernières cellules si vous voulez comparer le f1 score d svm avec celui de la regréssion logistique.\n",
    "# Testons pour une valeur plus grande de C.\n",
    "#model.set_params(C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5748537249477804\n"
     ]
    }
   ],
   "source": [
    "#model.fit(X_train,Y_train)\n",
    "#y_pred = model.predict(X_test)\n",
    "#f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "#print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=40, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testons pour une valeur plus grande de C.\n",
    "#model.set_params(C=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5936290856584262\n"
     ]
    }
   ],
   "source": [
    "#model.fit(X_train,Y_train)\n",
    "#y_pred = model.predict(X_test)\n",
    "#f1 = f1_score(Y_test,y_pred,average='macro')\n",
    "#print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On va garder une valeur de 10 pour le paramètre C.\n",
    "#model.set_params(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSvm = svm.SVC(kernel='linear')\n",
    "modelSvm.set_params(C=10)\n",
    "modelSvm.set_params(class_weight='balanced')\n",
    "modelSvm.fit(X_train, Y_train)\n",
    "y_pred_svm = modelSvm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5239676653528541\n"
     ]
    }
   ],
   "source": [
    "# le f1 score est inférieur à celui de la régression logistique.\n",
    "f1 = f1_score(Y_test,y_pred_svm,average='macro')\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
